---
title: "Initial Data Processing, Alpha Diversity and Beta Diversity Production"
author: "Mauna Dasari"
output: 
  html_document:
    theme: spacelab
    toc: true
    toc_depth: 6
    toc_float: true
---

```{r setup, include=FALSE, eval=T}
knitr::opts_chunk$set(echo = F, warning=F,message=F,cache=2)

library(tidyverse); library(kableExtra);library(knitr);
library(vegan);library(pander);library(dplyr)

```

This file will focus on processing the raw data file into clean data for the machine learning algorithms. The code for calculating alpha diversity is also in this file. Because the files are rather large, I've left in (but commented out) lines where an intermediate file was saved for quicker processing at later points. 

# Taxonomy Cleaning
```{r clean_taxonomy}
#silva_raw<-readRDS("Ch1/raw_data/IDTAXA_silva_assignment.rds")
silva_raw<-readRDS("../data/IDTAXA_silva_assignment.rds")

dim(silva_raw) #45350x7, the rows are seq and the col are taxa designations
silva<-as_tibble(silva_raw,rownames=NA) #convert it from a matrix to a tibble, preserve the rownames
silva$ASV<-rownames(silva)
#What's in the silva file?
silva$taxa_phyla<-paste(silva$domain,silva$phylum,sep="_")
silva$taxa_phyla<-gsub("-",".",silva$taxa_phyla)

silva$taxa_order<-paste(silva$domain,silva$phylum,silva$order, sep="_")
silva$taxa_order<-gsub("-",".",silva$taxa_order)

silva$taxa_family<-paste(silva$domain,silva$phylum,silva$order,silva$family, sep="_")
silva$taxa_family<-gsub("-",".",silva$taxa_family)

silva$taxa_genus<-paste(silva$domain,silva$phylum,silva$order,silva$family,silva$genus, sep="_")
silva$taxa_genus<-gsub("-",".",silva$taxa_genus)

silva$ASV_id<-paste("ASV",1:nrow(silva),sep=" ")
#adding ASV_id to simplify naming schemes 
saveRDS(silva,"../data/ASVs_silva_assigned.rds")

taxonomy<-silva%>%
  select(contains("taxa_"))
taxonomy$ASVs<-rownames(silva)
#saveRDS(taxonomy,"../data/taxonomy_assignment_clean.rds")
```

# Removing Singletons and Reads Mapped to Chloroplasts or Mitochondria
```{r data_wrangling.import_reads}
#Load the data!
reads_raw<-readRDS("../in/merged_baboon_data_with_metadata_preset_more_blanks_greater_1000.rds")

pres_abs<-reads_raw
pres_abs[pres_abs>0]<-1 #ASV as the colnames, sampleID as rownames
#saveRDS(pres_abs, "../out/presence_absence_raw.RDS")

#pres_abs<-readRDS("../data/presence_absence_raw.RDS")
pres_abs_t<-as.data.frame(t(pres_abs)) #transpose, samples are columns and rows are ASVs. 
pres_abs_t$ASVSum<-rowSums(pres_abs_t) #sum across the rows to find out if that ASV is a singleton or not.
pres_abs_t$ASVs<-rownames(pres_abs_t) #save the ASV names!
pres_abs_t2<-pres_abs_t%>%
    filter(ASVSum>2)#filter by singleton or doubleton status 
#saveRDS(pres_abs_t2, "../out/presence_absence_no_singletons_ASVSum_incl.RDS")
#pres_abs_t2<-readRDS("../out/presence_absence_no_singletons_ASVSum_incl.RDS")

#pres_abs<-readRDS("../data/presence_absence_no_singletons_ASVSum_incl.RDS")
#taxonomy<-readRDS("../data/taxonomy_assignment_clean.rds")
presabs_taxonomy<-merge(pres_abs, taxonomy, by="ASVs")

presabs_taxonomy_no_chl_mt<-presabs_taxonomy %>% 
  filter(taxa_order!="Bacteria_Cyanobacteria_Chloroplast") %>% 
  filter(taxa_family!="Bacteria_Proteobacteria_Rickettsiales_Mitochondria") #switches from 19182 to 19030, filtering out 152 ASVs
saveRDS(presabs_taxonomy_no_chl_mt,"../data/presabs_taxonomy_no_chl_mt.rds")

#filter our abundance table
readst<-as.data.frame(t(reads_raw))#transpose, samples are columns and rows are ASVs. 

readst$ASVs<-rownames(readst) #save the ASV names!
readst2<-readst%>%
    filter(ASVs %in% presabs_taxonomy_no_chl_mt$ASVs) 

rownames(readst2)<-readst2$ASVs
readst2<-readst2 %>% dplyr::select(c(-ASVs)) 

reads_final<-as.data.frame(t(readst2))

reads_final$DADA_id<-rownames(reads_final) #make the sample IDs accessible
#write_rds(reads_final, "../data/reads_intermediate_no_chl_mt.rds")
#reads3<-readRDS("../data/reads_intermediate_no_chl_mt.rds")
reads_taxonomy<-merge(reads_final,taxonomy,by="ASVs")
saveRDS(reads_taxonomy,"../data/reads_taxonomy.rds")

metadata<-readRDS("../data/metadata_full.rds")
monster_data<-merge(metadata, reads_final, by="DADA_id") 
#saveRDS(monster_data, "../out/ASV_and_metadata_full.rds")
```

# Alpha Diversity Metrics
```{r alpha_diversity}
monster_data2<-monster_data%>%dplyr::select(-c("sid","did","tid","DADA_id","plate","sname","extract_dna_conc_ng", "loading_plate_location","collection_date","sex","birth","bstatus","matured","matgrp"))%>%
    map_if(is.factor,as.character)%>%
    map_if(is.character,as.numeric)%>%
    as_data_frame

monster_data$read_count<-rowSums(monster_data2)

rsummary<-data.frame(DADA_id = monster_data$DADA_id,
                    read_count = monster_data$read_count)

#richness outputs a matrix
Rrichness<-estimateR(monster_data2) 
obs.richness<-Rrichness["S.obs",]
rsummary$richness<-obs.richness

#calculate Shannon's H
rsummary$ShannonH<-diversity(monster_data2,index="shannon")
beep(sound=5)
#And Simpson's, 1 is infinite diversity and 0 is no diversity
rsummary$Simpson<-diversity(monster_data2,index="simpson")
beep(sound=5)

Hill<-renyi(monster_data2, hill=T)*1 
rsummary$Hill.q1<-Hill$`1`
rsummary$Hill.q2<-Hill$`2`
alphadiv<-rsummary
```

The original dataset was comprised of 45,350 Amplicon Sequence Variants (ASVs) over 13,563 samples. After filtering for singletons, we have 16,258 ASVs over 13,563 samples. The highest number of reads in a sample was `r max(rsummary$total_reads)` and the lowest was `r min(rsummary$total_reads)` with a median read count of `r median(rsummary$total_reads)`. 

# Beta Diversity
This section was run on our HPCC. The entire script is included in the chunk below for this reason. 
```{r beta_div}
library(purrr);library(dplyr);library(vegan);library(labdsv);library(tibble)
raw_data<-readRDS("ASV_and_metadata_full.rds")
metadata<-readRDS("metadata_full.rds")
data<-raw_data[-14619,] #remove the ASVnames row
rownames(data)<-data$DADA_id
sample_IDs<-data$DADA_id

data_ASV<-data%>%dplyr::select(-c(colnames(metadata)))%>%
  map_if(is.factor,as.character)%>%
  map_if(is.character,as.numeric) 

data_ASV<-as.data.frame(data_ASV)

rownames(data_ASV)<-sample_IDs
data_ASVs<-colnames(data_ASV)
#Now the data is just DADA_id vs ASVs, and we have the rownames and colnames saved

t.data_ASV<-as.data.frame(t(data_ASV)) #switching it so that sample ID is the columns

#Need to do a singleton check for a subset like this.

t.data_ASV<-t.data_ASV%>%
  rownames_to_column("ASV") %>% 
  filter(rowSums(dplyr::select(., -ASV))>1)%>%
  column_to_rownames("ASV") #nothing should change, but this is just to be safe.

#Vegdist reqs quanties on species (column) vs sites (rows), so want samples as rows and ASVs as columns
data_ASV_no_singleton<-as.data.frame(t(t.data_ASV))
data_ASV_no_singleton_readcount_over1k<-data_ASV_no_singleton %>% 
  rownames_to_column("sample_ID") %>% 
  filter(rowSums(dplyr::select(., -sample_ID))>1000)%>%
  column_to_rownames("sample_ID") #making sure read count is reasonable, checks out

data_sample_IDs<-rownames(data_ASV_no_singleton_readcount_over1k)
data_ASVs<-colnames(data_ASV_no_singleton_readcount_over1k)

data.dis<-vegdist(data_ASV_no_singleton_readcount_over1k) 

data.mds<-metaMDS(data.dis,trace=0) #the vegan function is much slower than the labdsv function.
stressplot(data.mds)
NMDS.scores_ASVs_data<-as.data.frame(scores(data.mds))
NMDS.scores_ASVs_data$DADA_id<-rownames(NMDS.scores_ASVs_data)

data.pco<-pco(data.dis,k=10)
data_pcoa<-as.data.frame(data.pco$points)
colnames(data_pcoa)<-c("PC1","PC2","PC3","PC4","PC5","PC6","PC7","PC8","PC9","PC10")
data_pcoa$DADA_id<-rownames(data_pcoa)
barplot(data.pco$eig)
#(data.pco$eig[1]+data.pco$eig[2]+data.pco$eig[3]+data.pco$eig[4]+data.pco$eig[5]+data.pco$eig[6]+data.pco$eig[7]+data.pco$eig[8]+data.pco$eig[9]+data.pco$eig[10])/sum(data.pco$eig)
#saveRDS(data.pco,'2_beta/out/PCO_output.rds') #not sure I will actually be able to access this again, but worth trying to save 2 days
ordination_data<-merge(NMDS.scores_ASVs_data,data_pcoa,by="DADA_id")
saveRDS(ordination_data, "ordination_data.rds")
```

# CLR Transformation of Data
```{r}
#First create count tables for the phenotypes
taxonomy<-readRDS("../out/taxonomy_assignment_clean.rds")
reads_raw<-readRDS("../in/merged_baboon_data_with_metadata_preset_more_blanks_greater_1000.rds")
#pres_abs_t2<-readRDS("../out/presence_absence_no_singletons_ASVSum_incl.RDS")
pres_abs_no_chl_mt<-readRDS("../out/pres_abs_taxonomy_no_chl_mt.rds")
readst<-as.data.frame(t(reads_raw))
readst$ASVs<-rownames(readst) #save the ASV names!
readst2<-readst%>%
    filter(ASVs %in% pres_abs_no_chl_mt$ASVs) #filter the larger table by the smaller table

reads_taxonomy<-merge(readst2, taxonomy, by="ASVs") #table with 8566 ASVs

reads_phylum_long<-reads_taxonomy%>%
  group_by(taxa_phyla)%>%
  select(-c(taxa_order,taxa_genus,taxa_family)) %>% 
  gather(key=sample_ID, value=count,-taxa_phyla, -ASVs) %>%
  select(-ASVs) %>% 
  group_by(sample_ID,taxa_phyla)%>%
  summarize(count=sum(count)) %>%  #count all the taxa in that group
  mutate(rel_abundance = count / sum(count))%>% #calculate the relative abundance of all the taxa in that sample
  ungroup()

reads_phylum<-reads_phylum_long%>%
  select(-rel_abundance)%>%
  spread(key = sample_ID, value = count) 
rownames(reads_phylum)<-reads_phylum$taxa_phyla
reads_phylum<-select(reads_phylum,-taxa_phyla)
phylum_raw<-as.data.frame(t(reads_phylum))
#saveRDS(phylum_raw, "../out/counts_phylum_no_chl_mt.rds") 
phylum<-phylum_raw %>% rownames_to_column("DADA_id")
phenotypes<-phylum

reads_family<-reads_taxonomy%>%
  group_by(taxa_family)%>%
  select(-c(taxa_phyla,taxa_genus,taxa_order)) %>% 
  gather(key=sample_ID, value=count,-taxa_family, -ASVs) %>%
  select(-ASVs) %>% 
  group_by(sample_ID,taxa_family)%>%
  summarize(count=sum(count)) %>%  #count all the taxa in that group
  mutate(rel_abundance = count / sum(count))%>% #calculate the relative abundance of all the taxa in that sample
  select(-rel_abundance)%>%
  ungroup()%>%
  spread(key = sample_ID, value = count) 
rownames(reads_family)<-reads_family$taxa_family
reads_family<-select(reads_family,-taxa_family)
family_raw<-as.data.frame(t(reads_family))
#saveRDS(family_raw, "../out/counts_family_no_chl_mt.rds")
family<-family_raw %>% rownames_to_column("DADA_id")
phenotypes<-merge(phenotypes,family, by="DADA_id")

reads_genus<-reads_taxonomy%>%
  group_by(taxa_genus)%>%
  select(-c(taxa_phyla,taxa_order,taxa_family)) %>% 
  gather(key=sample_ID, value=count,-taxa_genus, -ASVs) %>%
  select(-ASVs) %>% 
  group_by(sample_ID,taxa_genus)%>%
  summarize(count=sum(count)) %>%  #count all the taxa in that group
  mutate(rel_abundance = count / sum(count))%>% #calculate the relative abundance of all the taxa in that sample
  select(-rel_abundance)%>%
  ungroup()%>%
  spread(key = sample_ID, value = count) 
rownames(reads_genus)<-reads_genus$taxa_genus
reads_genus<-select(reads_genus,-taxa_genus)
genus_raw<-as.data.frame(t(reads_genus))
#saveRDS(genus_raw, "../out/counts_genus_no_chl_mt.rds")
genus<-genus_raw %>% rownames_to_column("DADA_id")
phenotypes<-merge(phenotypes,genus, by="DADA_id")

ordination_raw<-readRDS("ordination_data.rds")
ordination<-ordination_raw%>%
  select(-c(contains("NMDS")))
colnames(ordination)[2:ncol(ordination)] = paste0("betadiv_",colnames(ordination)[2:ncol(ordination)])
betadiv_names<-colnames(ordination)[2:ncol(ordination)]
phenotypes<-merge(phenotypes,ordination, by="DADA_id")

phenotypes<-merge(phenotypes,alphadiv, by="DADA_id")

reads3<-readRDS("../out/reads_intermediate_no_chl_mt.rds")
DADA_id<-ASVcounts_raw$DADA_id
ASVcounts<-ASVcounts_raw%>% 
  select(-DADA_id) %>% 
  mutate_if(is.factor,as.character) %>% 
  mutate_if(is.character,as.numeric)
rownames(ASVcounts)<-DADA_id
ASVcounts$DADA_id<-DADA_id

phenotypes<-merge(phenotypes, ASVcounts, by="DADA_id")
saveRDS(phenotypes, 'phenotypes_readcounts_no_chl_mt.rds')

#the ordination table has negative values, so to get over this for the CLR transformation I'm adding 0.65 to all values in the phenotypes table.
#phenotypes<-readRDS('phenotypes_readcounts_no_chl_mt.rds')
phenotypes<-phenotypes %>% column_to_rownames("DADA_id")
phenotypes<-phenotypes+0.65

phenotypes[is.na(phenotypes)]<-0
phenotypes[phenotypes==0]<-0.65

##scale the train abundance table and save the values
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}

phenotypes_scaled_samplecols<-apply(phenotypes,1,function(x){log(x)/gm_mean(x)})
phenotypes_scaled<-as.data.frame(t(phenotypes_scaled_samplecols))
saveRDS(phenotypes_scaled, '../data/phenotypes_CLRscaled_no_chl_mt.rds')
```

# Data for ML Algorithms
RF and Gaussian process models were run in Python. To have readable data in both R and Python, I used the feather package.
```{r}
metadata_all<-readRDS("../data/metadata_full.rds")
#Filter out those with only one sample in the time frame.
##Figure out who those individuals are
metadata_filtered_no_singletons_lifespan<-metadata_all %>% 
  group_by(sname,sex,fake_sex) %>% 
  summarize(count=n_distinct(DADA_id)) %>% #479 individuals
  ungroup() %>% 
  filter(count>1) #431 individuals
##Filter out individuals not on the list
n_test=5 #5 for 80:20 split
info<-metadata_all %>% 
  select("DADA_id","sname","age.years","sex","fake_sex") %>%
  filter(sname %in% metadata_filtered_no_singletons_lifespan$sname) %>%
  group_by(sname) %>% 
  mutate(count=n(),
         testID=ifelse(count>n_test,
                       sample(1:n_test,size=count,replace=T),
                       sample(1:n_test,size=count,replace=F))) %>% 
  ungroup()
saveRDS(info,"../data/metadata_filtered_8020.rds")


metadata<-readRDS("../data/metadata_filtered_8020.rds")
meta<-metadata %>% select(DADA_id,sname,age.years, sex, testID) %>% arrange(DADA_id)
feather::write_feather(meta,"../data/metadata_filtered_8020_arranged.feather")

phenotypes<-readRDS("../data/phenotypes_CLRscaled_no_chl_mt.rds")
features<-phenotypes %>% 
  rownames_to_column("DADA_id") %>% 
  as.tibble() %>% 
  filter(.[['DADA_id']] %in% meta$DADA_id) %>% 
  arrange(.[['DADA_id']]) %>% distinct()
feather::write_feather(features,"../data/Features_arranged.feather")

library(feather)

phenotypes<-readRDS("../data/phenotypes_CLRscaled_no_chl_mt.rds")
#info<-readRDS("../../raw_data/metadata_filtered_8020.rds");n=5;folder="NestedCV8020";
info<-readRDS("../data/metadata_filtered_8020.rds") %>% 
  select(-fake_sex,-count)

for(i in 1:max(info$testID)){

#Filter the test and training data
train_info<-info %>% 
  filter(testID!=i) %>% 
  arrange(.[['DADA_id']])

test_info<-info %>% 
  filter(testID==i) %>% 
  arrange(.[['DADA_id']])

#Create features tables for both training and test data
train_count<-phenotypes %>% 
  rownames_to_column("DADA_id") %>% 
  as.tibble() %>% 
  filter(.[['DADA_id']] %in% train_info$DADA_id) %>% 
  arrange(.[['DADA_id']]) %>% 
  column_to_rownames("DADA_id")

test_count<-phenotypes %>% 
  rownames_to_column("DADA_id") %>% 
  as.tibble() %>% 
  filter(.[['DADA_id']] %in% test_info$DADA_id) %>% 
  arrange(.[['DADA_id']]) %>% 
  column_to_rownames("DADA_id") 


name_train_info<-paste("../data/metadata_Train",i,"_all.feather", sep="")
write_feather(train_info,name_train_info)
name_test_info<-paste("../data/metadata_Test",i,"_all.feather", sep="")
write_feather(test_info,name_test_info)
name_train_features<-paste("../data/features_Train",i,"_all.feather", sep="")
write_feather(train_count,name_train_features)
name_test_features<-paste("../data/features_Test",i,"_all.feather", sep="")
write_feather(test_count,name_test_features)
}
```